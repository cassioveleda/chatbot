{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# carregando os dados do Iris Dataset com sklearn\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "# obtendo as entradas e sa√≠das\n",
    "X, y = iris.data, iris.target\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybrain.datasets.classification import ClassificationDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ClassificationDataSet(4, 1, nb_classes=3)\n",
    "\n",
    "# adicionando as amostras\n",
    "for i in range(len(X)):\n",
    "    dataset.addSample(X[i], y[i])\n",
    "    \n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade para treino: 90\n",
      "Quantidade para teste: 30\n",
      "Quantidade para valida√ß√£o: 30\n"
     ]
    }
   ],
   "source": [
    "# particionando os dados para treinamento\n",
    "train_data, part_data = dataset.splitWithProportion(0.6)\n",
    "print('Quantidade para treino: %d' % len(train_data))\n",
    "\n",
    "# dividindo os dados para teste e valida√ß√£o\n",
    "test_data, val_data = part_data.splitWithProportion(0.5)\n",
    "print('Quantidade para teste: %d' % len(test_data))\n",
    "print('Quantidade para valida√ß√£o: %d' % len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.473603029959\n",
      "Total error:  0.363343443746\n",
      "Total error:  0.351622873228\n",
      "Total error:  0.350522253419\n",
      "Total error:  0.349161537956\n",
      "Total error:  0.348411637111\n",
      "Total error:  0.347410872588\n",
      "Total error:  0.345433658634\n",
      "Total error:  0.346569789622\n",
      "Total error:  0.345931399732\n",
      "Total error:  0.345004950835\n",
      "Total error:  0.343584028878\n",
      "Total error:  0.345735366866\n",
      "Total error:  0.343668981647\n",
      "Total error:  0.34437094109\n",
      "Total error:  0.342222604581\n",
      "Total error:  0.345699930564\n",
      "Total error:  0.344175497883\n",
      "Total error:  0.343600792572\n",
      "Total error:  0.342950618405\n",
      "Total error:  0.34120788619\n",
      "Total error:  0.34468384168\n",
      "Total error:  0.343927070606\n",
      "Total error:  0.343790627413\n",
      "Total error:  0.344504666721\n",
      "Total error:  0.344603062941\n",
      "Total error:  0.344201867889\n",
      "Total error:  0.344407041471\n",
      "Total error:  0.343947616964\n",
      "Total error:  0.343833177662\n",
      "Total error:  0.344648914913\n",
      "Total error:  0.34414590753\n",
      "Total error:  0.342284739005\n",
      "Total error:  0.344224566525\n",
      "Total error:  0.34390728792\n",
      "Total error:  0.344000985027\n",
      "Total error:  0.343008988549\n",
      "Total error:  0.343934745098\n",
      "Total error:  0.343361969577\n",
      "Total error:  0.341606363005\n",
      "Total error:  0.343724737998\n",
      "Total error:  0.341476341684\n",
      "Total error:  0.344090151454\n",
      "Total error:  0.343122233767\n",
      "Total error:  0.342960386738\n",
      "Total error:  0.343933046862\n",
      "Total error:  0.339125788822\n",
      "Total error:  0.344897228452\n",
      "Total error:  0.344212019647\n",
      "Total error:  0.343625941439\n",
      "Total error:  0.343727347246\n",
      "Total error:  0.343509086918\n",
      "Total error:  0.343550441707\n",
      "Total error:  0.342424506019\n",
      "Total error:  0.343186743793\n",
      "Total error:  0.341522031878\n",
      "Total error:  0.343952562668\n",
      "Total error:  0.343432167352\n",
      "Total error:  0.342586697256\n",
      "Total error:  0.342687249666\n",
      "Total error:  0.342957818304\n",
      "Total error:  0.34327213159\n",
      "Total error:  0.338290760271\n",
      "Total error:  0.343867290667\n",
      "Total error:  0.344687313631\n",
      "Total error:  0.342744985551\n",
      "Total error:  0.343639022461\n",
      "Total error:  0.34323467765\n",
      "Total error:  0.341913971062\n",
      "Total error:  0.342332073401\n",
      "Total error:  0.342708674065\n",
      "Total error:  0.341797941857\n",
      "Total error:  0.343075385642\n",
      "Total error:  0.343010298742\n",
      "Total error:  0.344000035334\n",
      "Total error:  0.343125230987\n",
      "Total error:  0.343543350307\n",
      "Total error:  0.343368326993\n",
      "Total error:  0.342926602138\n",
      "Total error:  0.343294221388\n",
      "Total error:  0.343121682937\n",
      "Total error:  0.34323698167\n",
      "Total error:  0.34360043621\n",
      "Total error:  0.342742064459\n",
      "Total error:  0.341890576386\n",
      "Total error:  0.343256606694\n",
      "Total error:  0.343282521287\n",
      "Total error:  0.340694189357\n",
      "Total error:  0.342745341474\n",
      "Total error:  0.341450635666\n",
      "Total error:  0.34357336771\n",
      "Total error:  0.34314991341\n",
      "Total error:  0.343269675068\n",
      "Total error:  0.341131582514\n",
      "Total error:  0.343766903205\n",
      "Total error:  0.342630856092\n",
      "Total error:  0.342451967852\n",
      "Total error:  0.343449109468\n",
      "Total error:  0.342710583565\n",
      "Total error:  0.343309160086\n",
      "Total error:  0.342608934868\n",
      "('train-errors:', '[0.473603 , 0.363343 , 0.351623 , 0.350522 , 0.349162 , 0.348412 , 0.347411 , 0.345434 , 0.34657  , 0.345931 , 0.345005 , 0.343584 , 0.345735 , 0.343669 , 0.344371 , 0.342223 , 0.3457   , 0.344175 , 0.343601 , 0.342951 , 0.341208 , 0.344684 , 0.343927 , 0.343791 , 0.344505 , 0.344603 , 0.344202 , 0.344407 , 0.343948 , 0.343833 , 0.344649 , 0.344146 , 0.342285 , 0.344225 , 0.343907 , 0.344001 , 0.343009 , 0.343935 , 0.343362 , 0.341606 , 0.343725 , 0.341476 , 0.34409  , 0.343122 , 0.34296  , 0.343933 , 0.339126 , 0.344897 , 0.344212 , 0.343626 , 0.343727 , 0.343509 , 0.34355  , 0.342425 , 0.343187 , 0.341522 , 0.343953 , 0.343432 , 0.342587 , 0.342687 , 0.342958 , 0.343272 , 0.338291 , 0.343867 , 0.344687 , 0.342745 , 0.343639 , 0.343235 , 0.341914 , 0.342332 , 0.342709 , 0.341798 , 0.343075 , 0.34301  , 0.344    , 0.343125 , 0.343543 , 0.343368 , 0.342927 , 0.343294 , 0.343122 , 0.343237 , 0.3436   , 0.342742 , 0.341891 , 0.343257 , 0.343283 , 0.340694 , 0.342745 , 0.341451 , 0.343573 , 0.34315  , 0.34327  , 0.341132 , 0.343767 , 0.342631 , 0.342452 , 0.343449 , 0.342711 , 0.343309 , 0.342609 ]')\n",
      "('valid-errors:', '[0.567599 , 0.348499 , 0.348518 , 0.354649 , 0.354253 , 0.35044  , 0.34858  , 0.352984 , 0.343129 , 0.350169 , 0.353675 , 0.349537 , 0.360328 , 0.348436 , 0.348862 , 0.352753 , 0.340233 , 0.345884 , 0.354408 , 0.34292  , 0.354271 , 0.340235 , 0.348973 , 0.346821 , 0.343615 , 0.349534 , 0.345845 , 0.344491 , 0.344681 , 0.347702 , 0.350594 , 0.348158 , 0.34476  , 0.339703 , 0.344706 , 0.345705 , 0.343508 , 0.343419 , 0.349172 , 0.345339 , 0.35442  , 0.352517 , 0.340328 , 0.345694 , 0.352513 , 0.355411 , 0.353922 , 0.338032 , 0.340583 , 0.344304 , 0.342109 , 0.347465 , 0.344158 , 0.341961 , 0.339762 , 0.341491 , 0.338439 , 0.347543 , 0.348606 , 0.344389 , 0.34983  , 0.342642 , 0.350112 , 0.337086 , 0.338245 , 0.344277 , 0.344972 , 0.348078 , 0.342197 , 0.338916 , 0.348721 , 0.351009 , 0.343652 , 0.348266 , 0.34285  , 0.344062 , 0.345491 , 0.348115 , 0.345521 , 0.35047  , 0.342808 , 0.347819 , 0.345501 , 0.344253 , 0.340042 , 0.345059 , 0.341954 , 0.347308 , 0.340054 , 0.341774 , 0.35409  , 0.351935 , 0.344448 , 0.344179 , 0.353913 , 0.350009 , 0.342529 , 0.341348 , 0.347566 , 0.350485 , 0.347405 , 0.345599 ]')\n"
     ]
    }
   ],
   "source": [
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "\n",
    "net = buildNetwork(dataset.indim, 3, dataset.outdim)\n",
    "trainer = BackpropTrainer(net, dataset=train_data, learningrate=0.01, momentum=0.1, verbose=True)\n",
    "train_errors, val_errors = trainer.trainUntilConvergence(dataset=train_data, maxEpochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_errors, 'b', val_errors, 'r')\n",
    "plt.show()\n",
    "\n",
    "trainer.totalepochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.343876743864\n",
      "Total error:  0.342135866101\n",
      "Total error:  0.338607194698\n",
      "Total error:  0.343766247623\n",
      "Total error:  0.344485081687\n",
      "Total error:  0.342842942701\n",
      "Total error:  0.34305416142\n",
      "Total error:  0.345299714972\n",
      "Total error:  0.343493156076\n",
      "Total error:  0.343944741913\n",
      "Total error:  0.344700995597\n",
      "Total error:  0.343922932811\n",
      "Total error:  0.34428932997\n",
      "Total error:  0.344644270834\n",
      "Total error:  0.345072513654\n",
      "Total error:  0.342321216525\n",
      "Total error:  0.339229661854\n",
      "Total error:  0.345304702478\n",
      "Total error:  0.343959831991\n",
      "Total error:  0.34481553399\n",
      "Total error:  0.343478993078\n",
      "Total error:  0.338389294771\n",
      "Total error:  0.345415840846\n",
      "Total error:  0.34450171844\n",
      "Total error:  0.344640614934\n",
      "Total error:  0.34508598207\n",
      "Total error:  0.341054560767\n",
      "Total error:  0.346024775821\n",
      "Total error:  0.345226297917\n",
      "Total error:  0.344676529838\n",
      "Total error:  0.344716221641\n",
      "Total error:  0.338707009401\n",
      "Total error:  0.344979773036\n",
      "Total error:  0.34203480187\n",
      "Total error:  0.340875195643\n",
      "Total error:  0.343972294812\n",
      "Total error:  0.342808274217\n",
      "Total error:  0.344337613879\n",
      "Total error:  0.34358690744\n",
      "Total error:  0.345149569627\n",
      "Total error:  0.344995571687\n",
      "Total error:  0.344967432855\n",
      "Total error:  0.341949606141\n",
      "Total error:  0.344998812145\n",
      "Total error:  0.343416759998\n",
      "Total error:  0.344322879667\n",
      "Total error:  0.340525416913\n",
      "Total error:  0.345693352291\n",
      "Total error:  0.343750507354\n",
      "Total error:  0.344356593344\n",
      "Total error:  0.344972261874\n",
      "Total error:  0.343575046545\n",
      "Total error:  0.342198627809\n",
      "Total error:  0.344736212481\n",
      "Total error:  0.343576331285\n",
      "Total error:  0.343894674776\n",
      "Total error:  0.343130521465\n",
      "Total error:  0.343264974434\n",
      "Total error:  0.343537550265\n",
      "Total error:  0.343909166898\n",
      "Total error:  0.341210735263\n",
      "Total error:  0.34208788617\n",
      "Total error:  0.343304835423\n",
      "Total error:  0.343699892014\n",
      "Total error:  0.344860884685\n",
      "Total error:  0.344633488242\n",
      "Total error:  0.344575151266\n",
      "Total error:  0.344950524358\n",
      "Total error:  0.344214756245\n",
      "Total error:  0.344705299979\n",
      "Total error:  0.341821811485\n",
      "Total error:  0.344711009933\n",
      "Total error:  0.344567846803\n",
      "Total error:  0.344158570537\n",
      "Total error:  0.344172522266\n",
      "Total error:  0.343094857754\n",
      "Total error:  0.34022496809\n",
      "Total error:  0.344318751012\n",
      "Total error:  0.344801775544\n",
      "Total error:  0.343830365045\n",
      "Total error:  0.343723774398\n",
      "Total error:  0.341798172764\n",
      "Total error:  0.344397225792\n",
      "Total error:  0.340750854381\n",
      "Total error:  0.345458045914\n",
      "Total error:  0.343409088311\n",
      "Total error:  0.345074129692\n",
      "Total error:  0.344170477849\n",
      "Total error:  0.340513572779\n",
      "Total error:  0.345006832046\n",
      "Total error:  0.343772987279\n",
      "Total error:  0.34460152199\n",
      "Total error:  0.34289149119\n",
      "Total error:  0.343673395496\n",
      "Total error:  0.342646278911\n",
      "Total error:  0.342461357945\n",
      "Total error:  0.345155831912\n",
      "Total error:  0.344009116142\n",
      "Total error:  0.343289423656\n",
      "Total error:  0.344421664628\n",
      "Total error:  0.343523678454\n",
      "Total error:  0.341663540364\n",
      "Total error:  0.34564771486\n",
      "Total error:  0.342378588407\n",
      "Total error:  0.344623597775\n",
      "Total error:  0.344462834397\n",
      "Total error:  0.34433737797\n",
      "Total error:  0.343156375419\n",
      "Total error:  0.344913841083\n",
      "Total error:  0.344505951185\n",
      "Total error:  0.342405945125\n",
      "Total error:  0.345819200187\n",
      "Total error:  0.344735635434\n",
      "Total error:  0.343678090933\n",
      "Total error:  0.345324436992\n",
      "Total error:  0.34473775489\n",
      "Total error:  0.344165677506\n",
      "Total error:  0.34269009677\n",
      "Total error:  0.343614450222\n",
      "Total error:  0.344767819788\n",
      "Total error:  0.343032935239\n",
      "Total error:  0.344977201486\n",
      "Total error:  0.344632732427\n",
      "Total error:  0.343680926001\n",
      "Total error:  0.344643975323\n",
      "Total error:  0.344354569708\n",
      "Total error:  0.343680423803\n",
      "Total error:  0.344357377648\n",
      "Total error:  0.344209514421\n",
      "Total error:  0.343257732987\n",
      "Total error:  0.344225378774\n",
      "Total error:  0.343153238967\n",
      "Total error:  0.343852093537\n",
      "Total error:  0.344808425749\n",
      "Total error:  0.343809413981\n",
      "Total error:  0.343767580726\n",
      "Total error:  0.341586600431\n",
      "Total error:  0.34458104178\n",
      "Total error:  0.3422807914\n",
      "Total error:  0.337561549369\n",
      "Total error:  0.34563127978\n",
      "Total error:  0.34147136203\n",
      "Total error:  0.345567338408\n",
      "Total error:  0.344334394476\n",
      "Total error:  0.344428504026\n",
      "Total error:  0.344979094569\n",
      "Total error:  0.344721200122\n",
      "Total error:  0.342758399457\n",
      "Total error:  0.344381478194\n",
      "Total error:  0.344537429986\n",
      "Total error:  0.34295183855\n",
      "Total error:  0.34393100934\n",
      "Total error:  0.339317704067\n",
      "Total error:  0.345306157401\n",
      "Total error:  0.343681682063\n",
      "Total error:  0.344409099089\n",
      "Total error:  0.344744520077\n",
      "Total error:  0.344607552457\n",
      "Total error:  0.344111860869\n",
      "Total error:  0.344013253867\n",
      "Total error:  0.344743098802\n",
      "Total error:  0.342507615116\n",
      "Total error:  0.341871547846\n",
      "Total error:  0.343405427585\n",
      "Total error:  0.343044356815\n",
      "Total error:  0.344332702129\n",
      "Total error:  0.342832795013\n",
      "Total error:  0.345015214881\n",
      "Total error:  0.341089218576\n",
      "Total error:  0.342634974856\n",
      "Total error:  0.343227709044\n",
      "Total error:  0.337788859712\n",
      "Total error:  0.344242724751\n",
      "Total error:  0.344735271283\n",
      "Total error:  0.344083552232\n",
      "Total error:  0.344001179811\n",
      "Total error:  0.344304497027\n",
      "Total error:  0.341398153405\n",
      "Total error:  0.343745017687\n",
      "Total error:  0.342838374526\n",
      "Total error:  0.344142701357\n",
      "Total error:  0.337583919211\n",
      "Total error:  0.345604355329\n",
      "Total error:  0.344851265349\n",
      "Total error:  0.343611052984\n",
      "Total error:  0.344584225101\n",
      "Total error:  0.343877599837\n",
      "Total error:  0.344741947492\n",
      "Total error:  0.344080629158\n",
      "Total error:  0.344074982018\n",
      "Total error:  0.342692525387\n",
      "Total error:  0.344952791152\n",
      "Total error:  0.344361525181\n",
      "Total error:  0.344240521619\n",
      "Total error:  0.344521658207\n",
      "Total error:  0.343479391862\n",
      "Total error:  0.343709173782\n",
      "Total error:  0.345426625968\n",
      "Total error:  0.343861881497\n",
      "Total error:  0.344995370507\n",
      "Total error:  0.343187938225\n",
      "Total error:  0.343986594949\n",
      "Total error:  0.344277865546\n",
      "Total error:  0.341051091987\n",
      "Total error:  0.344315508596\n",
      "Total error:  0.34184386427\n",
      "Total error:  0.344561120529\n",
      "Total error:  0.343529799064\n",
      "Total error:  0.342281670004\n",
      "Total error:  0.344544634881\n",
      "Total error:  0.340906739795\n",
      "Total error:  0.34458680845\n",
      "Total error:  0.344900988167\n",
      "Total error:  0.344383927588\n",
      "Total error:  0.343372640355\n",
      "Total error:  0.344952777528\n",
      "Total error:  0.343833929931\n",
      "Total error:  0.34165871797\n",
      "Total error:  0.342940160504\n",
      "Total error:  0.340486037564\n",
      "Total error:  0.344311087469\n",
      "Total error:  0.341642769671\n",
      "Total error:  0.343339462289\n",
      "Total error:  0.344102903617\n",
      "Total error:  0.343345951439\n",
      "Total error:  0.344890624427\n",
      "Total error:  0.344086370449\n",
      "Total error:  0.343667209099\n",
      "Total error:  0.337844165915\n",
      "Total error:  0.345628711843\n",
      "Total error:  0.34282932855\n",
      "Total error:  0.339140839975\n",
      "Total error:  0.34259529701\n",
      "Total error:  0.342833346743\n",
      "Total error:  0.344431953439\n",
      "Total error:  0.342363720968\n",
      "Total error:  0.344769147473\n",
      "Total error:  0.344517475442\n",
      "Total error:  0.337710601209\n",
      "Total error:  0.346825375207\n",
      "Total error:  0.34396397294\n",
      "Total error:  0.340560951406\n",
      "Total error:  0.344432140761\n",
      "Total error:  0.343387980299\n",
      "Total error:  0.344806378098\n",
      "Total error:  0.343105188331\n",
      "Total error:  0.34365325124\n",
      "Total error:  0.34498216688\n",
      "Total error:  0.343076367242\n",
      "Total error:  0.344506253433\n",
      "Total error:  0.343886287286\n",
      "Total error:  0.343414671532\n",
      "Total error:  0.342742896106\n",
      "Total error:  0.344619306713\n",
      "Total error:  0.343512783388\n",
      "Total error:  0.340337408018\n",
      "Total error:  0.343958058983\n",
      "Total error:  0.344417692267\n",
      "Total error:  0.342906153797\n",
      "Total error:  0.343300743789\n",
      "Total error:  0.342072616774\n",
      "Total error:  0.34588996358\n",
      "Total error:  0.344802250797\n",
      "Total error:  0.343452634657\n",
      "Total error:  0.344363535583\n",
      "Total error:  0.344273081697\n",
      "Total error:  0.3444503879\n",
      "Total error:  0.344339151601\n",
      "Total error:  0.342645786381\n",
      "Total error:  0.344123089601\n",
      "Total error:  0.344695710841\n",
      "Total error:  0.34386290131\n",
      "Total error:  0.344303500884\n",
      "Total error:  0.344517339686\n",
      "Total error:  0.340488307919\n",
      "Total error:  0.345899158003\n",
      "Total error:  0.341763010495\n",
      "Total error:  0.343725368376\n",
      "Total error:  0.343905039298\n",
      "Total error:  0.343003416762\n",
      "Total error:  0.343577960881\n",
      "Total error:  0.343424369543\n",
      "Total error:  0.343864144614\n",
      "Total error:  0.344516853437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.343876754131\n",
      "Total error:  0.344289319241\n",
      "Total error:  0.343283403282\n",
      "Total error:  0.341562359214\n",
      "Total error:  0.346094312191\n",
      "Total error:  0.342180595273\n",
      "Total error:  0.34494326184\n",
      "Total error:  0.344748257379\n",
      "Total error:  0.344159359531\n",
      "Total error:  0.344563090691\n",
      "Total error:  0.343685593723\n",
      "Total error:  0.342722180101\n",
      "Total error:  0.344401032461\n",
      "Total error:  0.34149065691\n",
      "Total error:  0.343827927664\n",
      "Total error:  0.343396475225\n",
      "Total error:  0.342094919699\n",
      "Total error:  0.345257500032\n",
      "Total error:  0.340133336579\n",
      "Total error:  0.342285963285\n",
      "Total error:  0.343433721493\n",
      "Total error:  0.342651348473\n",
      "Total error:  0.343868340912\n",
      "Total error:  0.344004525033\n",
      "Total error:  0.339408735858\n",
      "Total error:  0.345911350141\n",
      "Total error:  0.344707321039\n",
      "Total error:  0.343797698063\n",
      "Total error:  0.344043460475\n",
      "Total error:  0.340208634133\n",
      "Total error:  0.345689195958\n",
      "Total error:  0.344214785298\n",
      "Total error:  0.343926648187\n",
      "Total error:  0.344098309093\n",
      "Total error:  0.344180625923\n",
      "Total error:  0.344216377602\n",
      "Total error:  0.342063869509\n",
      "Total error:  0.343897811686\n",
      "Total error:  0.34354155457\n",
      "Total error:  0.344184483202\n",
      "Total error:  0.343282274956\n",
      "Total error:  0.343558521195\n",
      "Total error:  0.343549537528\n",
      "Total error:  0.343769267787\n",
      "Total error:  0.343283098019\n",
      "Total error:  0.344020559012\n",
      "Total error:  0.342908793067\n",
      "Total error:  0.344063600436\n",
      "Total error:  0.343609445681\n",
      "Total error:  0.342354399065\n",
      "Total error:  0.343190862403\n",
      "Total error:  0.343987231351\n",
      "Total error:  0.344385560647\n",
      "Total error:  0.344285284727\n",
      "Total error:  0.344081239954\n",
      "Total error:  0.34335100185\n",
      "Total error:  0.342878019267\n",
      "Total error:  0.341617768517\n",
      "Total error:  0.342418758341\n",
      "Total error:  0.344419115283\n",
      "Total error:  0.341972273199\n",
      "Total error:  0.342680704561\n",
      "Total error:  0.342399572115\n",
      "Total error:  0.341712069495\n",
      "Total error:  0.345611552232\n",
      "Total error:  0.343366578477\n",
      "Total error:  0.34403099895\n",
      "Total error:  0.340533410142\n",
      "Total error:  0.343168972\n",
      "Total error:  0.341799356836\n",
      "Total error:  0.344492783853\n",
      "Total error:  0.342020085206\n",
      "Total error:  0.344684891714\n",
      "Total error:  0.344580824641\n",
      "Total error:  0.343014432067\n",
      "Total error:  0.344486252198\n",
      "Total error:  0.344477692651\n",
      "Total error:  0.343057646048\n",
      "Total error:  0.342313847687\n",
      "Total error:  0.342644660265\n",
      "Total error:  0.345061858337\n",
      "Total error:  0.344244973162\n",
      "Total error:  0.341443145846\n",
      "Total error:  0.343492655074\n",
      "Total error:  0.342949430952\n",
      "Total error:  0.344132135224\n",
      "Total error:  0.344318448219\n",
      "Total error:  0.344279592557\n",
      "Total error:  0.343166077712\n",
      "Total error:  0.343387347716\n",
      "Total error:  0.344213814604\n",
      "Total error:  0.342915586415\n",
      "Total error:  0.344637420407\n",
      "Total error:  0.340414071642\n",
      "Total error:  0.344971155265\n",
      "Total error:  0.342894740535\n",
      "Total error:  0.344376374\n",
      "Total error:  0.343007344062\n",
      "Total error:  0.343143161275\n",
      "Total error:  0.344072983983\n",
      "Total error:  0.344001882589\n",
      "Total error:  0.342321675935\n",
      "Total error:  0.342928011308\n",
      "Total error:  0.344520253257\n",
      "Total error:  0.343722835351\n",
      "Total error:  0.342351707092\n",
      "Total error:  0.344537654062\n",
      "Total error:  0.343797980512\n",
      "Total error:  0.344302617519\n",
      "Total error:  0.343946007964\n",
      "Total error:  0.34398383046\n",
      "Total error:  0.343268023478\n",
      "Total error:  0.343383325398\n",
      "Total error:  0.343608698288\n",
      "Total error:  0.344311444183\n",
      "Total error:  0.343499382003\n",
      "Total error:  0.34073962195\n",
      "Total error:  0.342420930364\n",
      "Total error:  0.344167912116\n",
      "Total error:  0.342638406861\n",
      "Total error:  0.344083539933\n",
      "Total error:  0.343120767358\n",
      "Total error:  0.344734100322\n",
      "Total error:  0.344222587823\n",
      "Total error:  0.342810125798\n",
      "Total error:  0.343598905579\n",
      "Total error:  0.343995436448\n",
      "Total error:  0.344155125636\n",
      "Total error:  0.342553079268\n",
      "Total error:  0.342575131164\n",
      "Total error:  0.344054533168\n",
      "Total error:  0.343544396055\n",
      "Total error:  0.344387710765\n",
      "Total error:  0.342530540499\n",
      "Total error:  0.34462348997\n",
      "Total error:  0.343809381062\n",
      "Total error:  0.343155281947\n",
      "Total error:  0.343255447038\n",
      "Total error:  0.343725098804\n",
      "Total error:  0.343157988932\n",
      "Total error:  0.344245671019\n",
      "Total error:  0.341746185892\n",
      "Total error:  0.344376773096\n",
      "Total error:  0.343783070037\n",
      "Total error:  0.344364845294\n",
      "Total error:  0.341065682468\n",
      "Total error:  0.339297572285\n",
      "Total error:  0.343032021931\n",
      "Total error:  0.338726942873\n",
      "Total error:  0.345401999363\n",
      "Total error:  0.343586658083\n",
      "Total error:  0.343595284602\n",
      "Total error:  0.344105886217\n",
      "Total error:  0.341419885849\n",
      "Total error:  0.339123586085\n",
      "Total error:  0.342781773939\n",
      "Total error:  0.344600322924\n",
      "Total error:  0.344579855801\n",
      "Total error:  0.344552308319\n",
      "Total error:  0.344248005111\n",
      "Total error:  0.343390071571\n",
      "Total error:  0.343378406229\n",
      "Total error:  0.338418423651\n",
      "Total error:  0.344459200678\n",
      "Total error:  0.344617330925\n",
      "Total error:  0.344124280592\n",
      "Total error:  0.343998526667\n",
      "Total error:  0.344566903551\n",
      "Total error:  0.343865762016\n",
      "Total error:  0.341937570783\n",
      "Total error:  0.344671732564\n",
      "Total error:  0.341368507342\n",
      "Total error:  0.339831723211\n",
      "Total error:  0.341595576009\n",
      "Total error:  0.34333952619\n",
      "Total error:  0.344282793932\n",
      "Total error:  0.341552265249\n",
      "Total error:  0.344447829184\n",
      "Total error:  0.344980630525\n",
      "Total error:  0.343697933757\n",
      "Total error:  0.343847957849\n",
      "Total error:  0.34350656816\n",
      "Total error:  0.34273905706\n",
      "Total error:  0.344458270495\n",
      "Total error:  0.342895816747\n",
      "Total error:  0.342525403593\n",
      "Total error:  0.343894710946\n",
      "Total error:  0.344387407227\n",
      "Total error:  0.343559513572\n",
      "Total error:  0.34369384632\n",
      "Total error:  0.341556507469\n",
      "Total error:  0.344274725815\n",
      "Total error:  0.343871926596\n",
      "Total error:  0.344241342331\n",
      "Total error:  0.344653082229\n",
      "Total error:  0.343004041197\n",
      "Total error:  0.343512243284\n",
      "Total error:  0.344073311725\n",
      "Total error:  0.344583541848\n",
      "Total error:  0.342638606801\n",
      "Total error:  0.343078995095\n",
      "Total error:  0.342848018504\n",
      "Total error:  0.343466710397\n",
      "Total error:  0.344275995795\n",
      "Total error:  0.344692794987\n",
      "Total error:  0.344247533319\n",
      "Total error:  0.344331297499\n",
      "Total error:  0.34388900145\n",
      "Total error:  0.341310563355\n",
      "Total error:  0.344620963084\n",
      "Total error:  0.343366716942\n",
      "Total error:  0.342038235669\n",
      "Total error:  0.343811774634\n",
      "Total error:  0.341019378674\n",
      "Total error:  0.34106673585\n",
      "Total error:  0.345136162669\n"
     ]
    }
   ],
   "source": [
    "trainer.trainOnDataset(train_data, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: 0.898465, correct: 1.000000\n",
      "out: 0.898466, correct: 2.000000\n",
      "out: 0.898717, correct: 0.000000\n",
      "out: 0.898453, correct: 2.000000\n",
      "out: 0.898456, correct: 1.000000\n",
      "out: 0.898453, correct: 2.000000\n",
      "out: 0.898455, correct: 2.000000\n",
      "out: 0.898457, correct: 1.000000\n",
      "out: 0.898611, correct: 0.000000\n",
      "out: 0.898487, correct: 1.000000\n",
      "out: 0.898494, correct: 1.000000\n",
      "out: 0.898458, correct: 1.000000\n",
      "out: 0.898479, correct: 1.000000\n",
      "out: 0.898464, correct: 1.000000\n",
      "out: 0.898453, correct: 2.000000\n",
      "out: 0.898485, correct: 1.000000\n",
      "out: 0.898536, correct: 1.000000\n",
      "out: 0.898485, correct: 1.000000\n",
      "out: 0.898665, correct: 0.000000\n",
      "out: 0.898468, correct: 1.000000\n",
      "out: 0.898457, correct: 2.000000\n",
      "out: 0.898460, correct: 1.000000\n",
      "out: 0.898456, correct: 1.000000\n",
      "out: 0.898461, correct: 2.000000\n",
      "out: 0.898543, correct: 0.000000\n",
      "out: 0.898457, correct: 1.000000\n",
      "out: 0.898692, correct: 0.000000\n",
      "out: 0.898811, correct: 0.000000\n",
      "out: 0.898754, correct: 0.000000\n",
      "out: 0.898466, correct: 2.000000\n"
     ]
    }
   ],
   "source": [
    "out = net.activateOnDataset(test_data)\n",
    "for i in range(len(out)):\n",
    "    print('out: %f, correct: %f' % (out[i], test_data['target'][i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
